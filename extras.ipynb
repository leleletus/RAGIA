{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3a19f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEMINI_API_KEY found: True\n",
      "GEMINI_API_KEY (partial): AIza...\n",
      "--- MODELOS DISPONIBLES EN TU CUENTA ---\n",
      "--- MODELOS DISPONIBLES EN TU CUENTA ---\n",
      "Número de modelos recibidos: 54\n",
      "Modelo #1: name=models/embedding-gecko-001\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Obtain a distributed representation of a text.',\n",
      "  display_name='Embedding Gecko',\n",
      "  input_token_limit=1024,\n",
      "  name='models/embedding-gecko-001',\n",
      "  output_token_limit=1,\n",
      "  supported_actions=[\n",
      "    'embedText',\n",
      "    'countTextTokens',\n",
      "  ],\n",
      "  tuned_model_info=TunedModelInfo(),\n",
      "  ve\n",
      "Modelo #2: name=models/gemini-2.5-flash\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Stable version of Gemini 2.5 Flash, our mid-size multimodal model that supports up to 1 million tokens, released in June of 2025.',\n",
      "  display_name='Gemini 2.5 Flash',\n",
      "  input_token_limit=1048576,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-2.5-flash',\n",
      "  output_token_limit=6553\n",
      "Modelo #3: name=models/gemini-2.5-pro\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Stable release (June 17th, 2025) of Gemini 2.5 Pro',\n",
      "  display_name='Gemini 2.5 Pro',\n",
      "  input_token_limit=1048576,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-2.5-pro',\n",
      "  output_token_limit=65536,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'countTokens',\n",
      "    'createCache\n",
      "Modelo #4: name=models/gemini-2.0-flash-exp\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Gemini 2.0 Flash Experimental',\n",
      "  display_name='Gemini 2.0 Flash Experimental',\n",
      "  input_token_limit=1048576,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-2.0-flash-exp',\n",
      "  output_token_limit=8192,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'countTokens',\n",
      "    'bidiGenerate\n",
      "Modelo #5: name=models/gemini-2.0-flash\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Gemini 2.0 Flash',\n",
      "  display_name='Gemini 2.0 Flash',\n",
      "  input_token_limit=1048576,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-2.0-flash',\n",
      "  output_token_limit=8192,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'countTokens',\n",
      "    'createCachedContent',\n",
      "    'batchGenerateCo\n",
      "Modelo #6: name=models/gemini-2.0-flash-001\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Stable version of Gemini 2.0 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in January of 2025.',\n",
      "  display_name='Gemini 2.0 Flash 001',\n",
      "  input_token_limit=1048576,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-2.0-flash-001',\n",
      "  output\n",
      "Modelo #7: name=models/gemini-2.0-flash-exp-image-generation\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Gemini 2.0 Flash (Image Generation) Experimental',\n",
      "  display_name='Gemini 2.0 Flash (Image Generation) Experimental',\n",
      "  input_token_limit=1048576,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-2.0-flash-exp-image-generation',\n",
      "  output_token_limit=8192,\n",
      "  supported_actions=[\n",
      "    \n",
      "Modelo #8: name=models/gemini-2.0-flash-lite-001\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Stable version of Gemini 2.0 Flash-Lite',\n",
      "  display_name='Gemini 2.0 Flash-Lite 001',\n",
      "  input_token_limit=1048576,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-2.0-flash-lite-001',\n",
      "  output_token_limit=8192,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'countTokens',\n",
      "    'c\n",
      "Modelo #9: name=models/gemini-2.0-flash-lite\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Gemini 2.0 Flash-Lite',\n",
      "  display_name='Gemini 2.0 Flash-Lite',\n",
      "  input_token_limit=1048576,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-2.0-flash-lite',\n",
      "  output_token_limit=8192,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'countTokens',\n",
      "    'createCachedContent',\n",
      "    '\n",
      "Modelo #10: name=models/gemini-2.0-flash-lite-preview-02-05\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Preview release (February 5th, 2025) of Gemini 2.0 Flash-Lite',\n",
      "  display_name='Gemini 2.0 Flash-Lite Preview 02-05',\n",
      "  input_token_limit=1048576,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-2.0-flash-lite-preview-02-05',\n",
      "  output_token_limit=8192,\n",
      "  supported_actions=[\n",
      "    'g\n",
      "Modelo #11: name=models/gemini-2.0-flash-lite-preview\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Preview release (February 5th, 2025) of Gemini 2.0 Flash-Lite',\n",
      "  display_name='Gemini 2.0 Flash-Lite Preview',\n",
      "  input_token_limit=1048576,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-2.0-flash-lite-preview',\n",
      "  output_token_limit=8192,\n",
      "  supported_actions=[\n",
      "    'generateConte\n",
      "Modelo #12: name=models/gemini-exp-1206\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro',\n",
      "  display_name='Gemini Experimental 1206',\n",
      "  input_token_limit=1048576,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-exp-1206',\n",
      "  output_token_limit=65536,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'countTokens'\n",
      "Modelo #13: name=models/gemini-2.5-flash-preview-tts\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Gemini 2.5 Flash Preview TTS',\n",
      "  display_name='Gemini 2.5 Flash Preview TTS',\n",
      "  input_token_limit=8192,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-2.5-flash-preview-tts',\n",
      "  output_token_limit=16384,\n",
      "  supported_actions=[\n",
      "    'countTokens',\n",
      "    'generateContent',\n",
      "  ],\n",
      "  temper\n",
      "Modelo #14: name=models/gemini-2.5-pro-preview-tts\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Gemini 2.5 Pro Preview TTS',\n",
      "  display_name='Gemini 2.5 Pro Preview TTS',\n",
      "  input_token_limit=8192,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-2.5-pro-preview-tts',\n",
      "  output_token_limit=16384,\n",
      "  supported_actions=[\n",
      "    'countTokens',\n",
      "    'generateContent',\n",
      "    'batchGenerateC\n",
      "Modelo #15: name=models/gemma-3-1b-it\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  display_name='Gemma 3 1B',\n",
      "  input_token_limit=32768,\n",
      "  name='models/gemma-3-1b-it',\n",
      "  output_token_limit=8192,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'countTokens',\n",
      "  ],\n",
      "  temperature=1.0,\n",
      "  top_k=64,\n",
      "  top_p=0.95,\n",
      "  tuned_model_info=TunedModelInfo(),\n",
      "  version='001'\n",
      ")\n",
      "Modelo #16: name=models/gemma-3-4b-it\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  display_name='Gemma 3 4B',\n",
      "  input_token_limit=32768,\n",
      "  name='models/gemma-3-4b-it',\n",
      "  output_token_limit=8192,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'countTokens',\n",
      "  ],\n",
      "  temperature=1.0,\n",
      "  top_k=64,\n",
      "  top_p=0.95,\n",
      "  tuned_model_info=TunedModelInfo(),\n",
      "  version='001'\n",
      ")\n",
      "Modelo #17: name=models/gemma-3-12b-it\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  display_name='Gemma 3 12B',\n",
      "  input_token_limit=32768,\n",
      "  name='models/gemma-3-12b-it',\n",
      "  output_token_limit=8192,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'countTokens',\n",
      "  ],\n",
      "  temperature=1.0,\n",
      "  top_k=64,\n",
      "  top_p=0.95,\n",
      "  tuned_model_info=TunedModelInfo(),\n",
      "  version='001'\n",
      ")\n",
      "Modelo #18: name=models/gemma-3-27b-it\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  display_name='Gemma 3 27B',\n",
      "  input_token_limit=131072,\n",
      "  name='models/gemma-3-27b-it',\n",
      "  output_token_limit=8192,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'countTokens',\n",
      "  ],\n",
      "  temperature=1.0,\n",
      "  top_k=64,\n",
      "  top_p=0.95,\n",
      "  tuned_model_info=TunedModelInfo(),\n",
      "  version='001'\n",
      ")\n",
      "Modelo #19: name=models/gemma-3n-e4b-it\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  display_name='Gemma 3n E4B',\n",
      "  input_token_limit=8192,\n",
      "  name='models/gemma-3n-e4b-it',\n",
      "  output_token_limit=2048,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'countTokens',\n",
      "  ],\n",
      "  temperature=1.0,\n",
      "  top_k=64,\n",
      "  top_p=0.95,\n",
      "  tuned_model_info=TunedModelInfo(),\n",
      "  version='001'\n",
      ")\n",
      "Modelo #20: name=models/gemma-3n-e2b-it\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  display_name='Gemma 3n E2B',\n",
      "  input_token_limit=8192,\n",
      "  name='models/gemma-3n-e2b-it',\n",
      "  output_token_limit=2048,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'countTokens',\n",
      "  ],\n",
      "  temperature=1.0,\n",
      "  top_k=64,\n",
      "  top_p=0.95,\n",
      "  tuned_model_info=TunedModelInfo(),\n",
      "  version='001'\n",
      ")\n",
      "Modelo #21: name=models/gemini-flash-latest\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Latest release of Gemini Flash',\n",
      "  display_name='Gemini Flash Latest',\n",
      "  input_token_limit=1048576,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-flash-latest',\n",
      "  output_token_limit=65536,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'countTokens',\n",
      "    'createCachedContent',\n",
      "Modelo #22: name=models/gemini-flash-lite-latest\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Latest release of Gemini Flash-Lite',\n",
      "  display_name='Gemini Flash-Lite Latest',\n",
      "  input_token_limit=1048576,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-flash-lite-latest',\n",
      "  output_token_limit=65536,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'countTokens',\n",
      "    'create\n",
      "Modelo #23: name=models/gemini-pro-latest\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Latest release of Gemini Pro',\n",
      "  display_name='Gemini Pro Latest',\n",
      "  input_token_limit=1048576,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-pro-latest',\n",
      "  output_token_limit=65536,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'countTokens',\n",
      "    'createCachedContent',\n",
      "    '\n",
      "Modelo #24: name=models/gemini-2.5-flash-lite\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Stable version of Gemini 2.5 Flash-Lite, released in July of 2025',\n",
      "  display_name='Gemini 2.5 Flash-Lite',\n",
      "  input_token_limit=1048576,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-2.5-flash-lite',\n",
      "  output_token_limit=65536,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'c\n",
      "Modelo #25: name=models/gemini-2.5-flash-image-preview\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Gemini 2.5 Flash Preview Image',\n",
      "  display_name='Nano Banana',\n",
      "  input_token_limit=32768,\n",
      "  max_temperature=1.0,\n",
      "  name='models/gemini-2.5-flash-image-preview',\n",
      "  output_token_limit=32768,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'countTokens',\n",
      "    'batchGenerateContent\n",
      "Modelo #26: name=models/gemini-2.5-flash-image\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Gemini 2.5 Flash Preview Image',\n",
      "  display_name='Nano Banana',\n",
      "  input_token_limit=32768,\n",
      "  max_temperature=1.0,\n",
      "  name='models/gemini-2.5-flash-image',\n",
      "  output_token_limit=32768,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'countTokens',\n",
      "    'batchGenerateContent',\n",
      "  ],\n",
      "\n",
      "Modelo #27: name=models/gemini-2.5-flash-preview-09-2025\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Gemini 2.5 Flash Preview Sep 2025',\n",
      "  display_name='Gemini 2.5 Flash Preview Sep 2025',\n",
      "  input_token_limit=1048576,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-2.5-flash-preview-09-2025',\n",
      "  output_token_limit=65536,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'countToken\n",
      "Modelo #28: name=models/gemini-2.5-flash-lite-preview-09-2025\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Preview release (Septempber 25th, 2025) of Gemini 2.5 Flash-Lite',\n",
      "  display_name='Gemini 2.5 Flash-Lite Preview Sep 2025',\n",
      "  input_token_limit=1048576,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-2.5-flash-lite-preview-09-2025',\n",
      "  output_token_limit=65536,\n",
      "  supported_actions\n",
      "Modelo #29: name=models/gemini-3-pro-preview\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Gemini 3 Pro Preview',\n",
      "  display_name='Gemini 3 Pro Preview',\n",
      "  input_token_limit=1048576,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-3-pro-preview',\n",
      "  output_token_limit=65536,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'countTokens',\n",
      "    'createCachedContent',\n",
      "    'ba\n",
      "Modelo #30: name=models/gemini-3-flash-preview\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Gemini 3 Flash Preview',\n",
      "  display_name='Gemini 3 Flash Preview',\n",
      "  input_token_limit=1048576,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-3-flash-preview',\n",
      "  output_token_limit=65536,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'countTokens',\n",
      "    'createCachedContent',\n",
      " \n",
      "Modelo #31: name=models/gemini-3-pro-image-preview\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Gemini 3 Pro Image Preview',\n",
      "  display_name='Nano Banana Pro',\n",
      "  input_token_limit=131072,\n",
      "  max_temperature=1.0,\n",
      "  name='models/gemini-3-pro-image-preview',\n",
      "  output_token_limit=32768,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'countTokens',\n",
      "    'batchGenerateContent',\n",
      "\n",
      "Modelo #32: name=models/nano-banana-pro-preview\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Gemini 3 Pro Image Preview',\n",
      "  display_name='Nano Banana Pro',\n",
      "  input_token_limit=131072,\n",
      "  max_temperature=1.0,\n",
      "  name='models/nano-banana-pro-preview',\n",
      "  output_token_limit=32768,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'countTokens',\n",
      "    'batchGenerateContent',\n",
      "  ]\n",
      "Modelo #33: name=models/gemini-robotics-er-1.5-preview\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Gemini Robotics-ER 1.5 Preview',\n",
      "  display_name='Gemini Robotics-ER 1.5 Preview',\n",
      "  input_token_limit=1048576,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-robotics-er-1.5-preview',\n",
      "  output_token_limit=65536,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'countTokens',\n",
      "  ],\n",
      "Modelo #34: name=models/gemini-2.5-computer-use-preview-10-2025\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Gemini 2.5 Computer Use Preview 10-2025',\n",
      "  display_name='Gemini 2.5 Computer Use Preview 10-2025',\n",
      "  input_token_limit=131072,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-2.5-computer-use-preview-10-2025',\n",
      "  output_token_limit=65536,\n",
      "  supported_actions=[\n",
      "    'generateContent\n",
      "Modelo #35: name=models/deep-research-pro-preview-12-2025\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Preview release (December 12th, 2025) of Deep Research Pro',\n",
      "  display_name='Deep Research Pro Preview (Dec-12-2025)',\n",
      "  input_token_limit=131072,\n",
      "  max_temperature=2.0,\n",
      "  name='models/deep-research-pro-preview-12-2025',\n",
      "  output_token_limit=65536,\n",
      "  supported_actions=[\n",
      "    'ge\n",
      "Modelo #36: name=models/embedding-001\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Obtain a distributed representation of a text.',\n",
      "  display_name='Embedding 001',\n",
      "  input_token_limit=2048,\n",
      "  name='models/embedding-001',\n",
      "  output_token_limit=1,\n",
      "  supported_actions=[\n",
      "    'embedContent',\n",
      "  ],\n",
      "  tuned_model_info=TunedModelInfo(),\n",
      "  version='001'\n",
      ")\n",
      "Modelo #37: name=models/text-embedding-004\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Obtain a distributed representation of a text.',\n",
      "  display_name='Text Embedding 004',\n",
      "  input_token_limit=2048,\n",
      "  name='models/text-embedding-004',\n",
      "  output_token_limit=1,\n",
      "  supported_actions=[\n",
      "    'embedContent',\n",
      "  ],\n",
      "  tuned_model_info=TunedModelInfo(),\n",
      "  version='004'\n",
      ")\n",
      "Modelo #38: name=models/gemini-embedding-exp-03-07\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Obtain a distributed representation of a text.',\n",
      "  display_name='Gemini Embedding Experimental 03-07',\n",
      "  input_token_limit=8192,\n",
      "  name='models/gemini-embedding-exp-03-07',\n",
      "  output_token_limit=1,\n",
      "  supported_actions=[\n",
      "    'embedContent',\n",
      "    'countTextTokens',\n",
      "    'countTokens\n",
      "Modelo #39: name=models/gemini-embedding-exp\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Obtain a distributed representation of a text.',\n",
      "  display_name='Gemini Embedding Experimental',\n",
      "  input_token_limit=8192,\n",
      "  name='models/gemini-embedding-exp',\n",
      "  output_token_limit=1,\n",
      "  supported_actions=[\n",
      "    'embedContent',\n",
      "    'countTextTokens',\n",
      "    'countTokens',\n",
      "  ],\n",
      "  tu\n",
      "Modelo #40: name=models/gemini-embedding-001\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Obtain a distributed representation of a text.',\n",
      "  display_name='Gemini Embedding 001',\n",
      "  input_token_limit=2048,\n",
      "  name='models/gemini-embedding-001',\n",
      "  output_token_limit=1,\n",
      "  supported_actions=[\n",
      "    'embedContent',\n",
      "    'countTextTokens',\n",
      "    'countTokens',\n",
      "    'asyncBatchEmb\n",
      "Modelo #41: name=models/aqa\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Model trained to return answers to questions that are grounded in provided sources, along with estimating answerable probability.',\n",
      "  display_name='Model that performs Attributed Question Answering.',\n",
      "  input_token_limit=7168,\n",
      "  name='models/aqa',\n",
      "  output_token_limit=1024,\n",
      "  s\n",
      "Modelo #42: name=models/imagen-4.0-generate-preview-06-06\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Vertex served Imagen 4.0 model',\n",
      "  display_name='Imagen 4 (Preview)',\n",
      "  input_token_limit=480,\n",
      "  name='models/imagen-4.0-generate-preview-06-06',\n",
      "  output_token_limit=8192,\n",
      "  supported_actions=[\n",
      "    'predict',\n",
      "  ],\n",
      "  tuned_model_info=TunedModelInfo(),\n",
      "  version='01'\n",
      ")\n",
      "Modelo #43: name=models/imagen-4.0-ultra-generate-preview-06-06\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Vertex served Imagen 4.0 ultra model',\n",
      "  display_name='Imagen 4 Ultra (Preview)',\n",
      "  input_token_limit=480,\n",
      "  name='models/imagen-4.0-ultra-generate-preview-06-06',\n",
      "  output_token_limit=8192,\n",
      "  supported_actions=[\n",
      "    'predict',\n",
      "  ],\n",
      "  tuned_model_info=TunedModelInfo(),\n",
      "  versio\n",
      "Modelo #44: name=models/imagen-4.0-generate-001\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Vertex served Imagen 4.0 model',\n",
      "  display_name='Imagen 4',\n",
      "  input_token_limit=480,\n",
      "  name='models/imagen-4.0-generate-001',\n",
      "  output_token_limit=8192,\n",
      "  supported_actions=[\n",
      "    'predict',\n",
      "  ],\n",
      "  tuned_model_info=TunedModelInfo(),\n",
      "  version='001'\n",
      ")\n",
      "Modelo #45: name=models/imagen-4.0-ultra-generate-001\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Vertex served Imagen 4.0 ultra model',\n",
      "  display_name='Imagen 4 Ultra',\n",
      "  input_token_limit=480,\n",
      "  name='models/imagen-4.0-ultra-generate-001',\n",
      "  output_token_limit=8192,\n",
      "  supported_actions=[\n",
      "    'predict',\n",
      "  ],\n",
      "  tuned_model_info=TunedModelInfo(),\n",
      "  version='001'\n",
      ")\n",
      "Modelo #46: name=models/imagen-4.0-fast-generate-001\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Vertex served Imagen 4.0 Fast model',\n",
      "  display_name='Imagen 4 Fast',\n",
      "  input_token_limit=480,\n",
      "  name='models/imagen-4.0-fast-generate-001',\n",
      "  output_token_limit=8192,\n",
      "  supported_actions=[\n",
      "    'predict',\n",
      "  ],\n",
      "  tuned_model_info=TunedModelInfo(),\n",
      "  version='001'\n",
      ")\n",
      "Modelo #47: name=models/veo-2.0-generate-001\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Vertex served Veo 2 model. Access to this model requires billing to be enabled on the associated Google Cloud Platform account. Please visit https://console.cloud.google.com/billing to enable it.',\n",
      "  display_name='Veo 2',\n",
      "  input_token_limit=480,\n",
      "  name='models/veo-2.0-generate\n",
      "Modelo #48: name=models/veo-3.0-generate-001\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Veo 3',\n",
      "  display_name='Veo 3',\n",
      "  input_token_limit=480,\n",
      "  name='models/veo-3.0-generate-001',\n",
      "  output_token_limit=8192,\n",
      "  supported_actions=[\n",
      "    'predictLongRunning',\n",
      "  ],\n",
      "  tuned_model_info=TunedModelInfo(),\n",
      "  version='3.0'\n",
      ")\n",
      "Modelo #49: name=models/veo-3.0-fast-generate-001\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Veo 3 fast',\n",
      "  display_name='Veo 3 fast',\n",
      "  input_token_limit=480,\n",
      "  name='models/veo-3.0-fast-generate-001',\n",
      "  output_token_limit=8192,\n",
      "  supported_actions=[\n",
      "    'predictLongRunning',\n",
      "  ],\n",
      "  tuned_model_info=TunedModelInfo(),\n",
      "  version='3.0'\n",
      ")\n",
      "Modelo #50: name=models/veo-3.1-generate-preview\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Veo 3.1',\n",
      "  display_name='Veo 3.1',\n",
      "  input_token_limit=480,\n",
      "  name='models/veo-3.1-generate-preview',\n",
      "  output_token_limit=8192,\n",
      "  supported_actions=[\n",
      "    'predictLongRunning',\n",
      "  ],\n",
      "  tuned_model_info=TunedModelInfo(),\n",
      "  version='3.1'\n",
      ")\n",
      "Modelo #51: name=models/veo-3.1-fast-generate-preview\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Veo 3.1 fast',\n",
      "  display_name='Veo 3.1 fast',\n",
      "  input_token_limit=480,\n",
      "  name='models/veo-3.1-fast-generate-preview',\n",
      "  output_token_limit=8192,\n",
      "  supported_actions=[\n",
      "    'predictLongRunning',\n",
      "  ],\n",
      "  tuned_model_info=TunedModelInfo(),\n",
      "  version='3.1'\n",
      ")\n",
      "Modelo #52: name=models/gemini-2.5-flash-native-audio-latest\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Latest release of Gemini 2.5 Flash Native Audio',\n",
      "  display_name='Gemini 2.5 Flash Native Audio Latest',\n",
      "  input_token_limit=131072,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-2.5-flash-native-audio-latest',\n",
      "  output_token_limit=8192,\n",
      "  supported_actions=[\n",
      "    'countTokens',\n",
      "\n",
      "Modelo #53: name=models/gemini-2.5-flash-native-audio-preview-09-2025\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Gemini 2.5 Flash Native Audio Preview 09-2025',\n",
      "  display_name='Gemini 2.5 Flash Native Audio Preview 09-2025',\n",
      "  input_token_limit=131072,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-2.5-flash-native-audio-preview-09-2025',\n",
      "  output_token_limit=8192,\n",
      "  supported_actions=[\n",
      "   \n",
      "Modelo #54: name=models/gemini-2.5-flash-native-audio-preview-12-2025\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Gemini 2.5 Flash Native Audio Preview 12-2025',\n",
      "  display_name='Gemini 2.5 Flash Native Audio Preview 12-2025',\n",
      "  input_token_limit=131072,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-2.5-flash-native-audio-preview-12-2025',\n",
      "  output_token_limit=8192,\n",
      "  supported_actions=[\n",
      "   \n",
      "--- FIN DIAGNÓSTICO ---\n",
      "Número de modelos recibidos: 54\n",
      "Modelo #1: name=models/embedding-gecko-001\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Obtain a distributed representation of a text.',\n",
      "  display_name='Embedding Gecko',\n",
      "  input_token_limit=1024,\n",
      "  name='models/embedding-gecko-001',\n",
      "  output_token_limit=1,\n",
      "  supported_actions=[\n",
      "    'embedText',\n",
      "    'countTextTokens',\n",
      "  ],\n",
      "  tuned_model_info=TunedModelInfo(),\n",
      "  ve\n",
      "Modelo #2: name=models/gemini-2.5-flash\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Stable version of Gemini 2.5 Flash, our mid-size multimodal model that supports up to 1 million tokens, released in June of 2025.',\n",
      "  display_name='Gemini 2.5 Flash',\n",
      "  input_token_limit=1048576,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-2.5-flash',\n",
      "  output_token_limit=6553\n",
      "Modelo #3: name=models/gemini-2.5-pro\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Stable release (June 17th, 2025) of Gemini 2.5 Pro',\n",
      "  display_name='Gemini 2.5 Pro',\n",
      "  input_token_limit=1048576,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-2.5-pro',\n",
      "  output_token_limit=65536,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'countTokens',\n",
      "    'createCache\n",
      "Modelo #4: name=models/gemini-2.0-flash-exp\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Gemini 2.0 Flash Experimental',\n",
      "  display_name='Gemini 2.0 Flash Experimental',\n",
      "  input_token_limit=1048576,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-2.0-flash-exp',\n",
      "  output_token_limit=8192,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'countTokens',\n",
      "    'bidiGenerate\n",
      "Modelo #5: name=models/gemini-2.0-flash\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Gemini 2.0 Flash',\n",
      "  display_name='Gemini 2.0 Flash',\n",
      "  input_token_limit=1048576,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-2.0-flash',\n",
      "  output_token_limit=8192,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'countTokens',\n",
      "    'createCachedContent',\n",
      "    'batchGenerateCo\n",
      "Modelo #6: name=models/gemini-2.0-flash-001\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Stable version of Gemini 2.0 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in January of 2025.',\n",
      "  display_name='Gemini 2.0 Flash 001',\n",
      "  input_token_limit=1048576,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-2.0-flash-001',\n",
      "  output\n",
      "Modelo #7: name=models/gemini-2.0-flash-exp-image-generation\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Gemini 2.0 Flash (Image Generation) Experimental',\n",
      "  display_name='Gemini 2.0 Flash (Image Generation) Experimental',\n",
      "  input_token_limit=1048576,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-2.0-flash-exp-image-generation',\n",
      "  output_token_limit=8192,\n",
      "  supported_actions=[\n",
      "    \n",
      "Modelo #8: name=models/gemini-2.0-flash-lite-001\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Stable version of Gemini 2.0 Flash-Lite',\n",
      "  display_name='Gemini 2.0 Flash-Lite 001',\n",
      "  input_token_limit=1048576,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-2.0-flash-lite-001',\n",
      "  output_token_limit=8192,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'countTokens',\n",
      "    'c\n",
      "Modelo #9: name=models/gemini-2.0-flash-lite\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Gemini 2.0 Flash-Lite',\n",
      "  display_name='Gemini 2.0 Flash-Lite',\n",
      "  input_token_limit=1048576,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-2.0-flash-lite',\n",
      "  output_token_limit=8192,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'countTokens',\n",
      "    'createCachedContent',\n",
      "    '\n",
      "Modelo #10: name=models/gemini-2.0-flash-lite-preview-02-05\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Preview release (February 5th, 2025) of Gemini 2.0 Flash-Lite',\n",
      "  display_name='Gemini 2.0 Flash-Lite Preview 02-05',\n",
      "  input_token_limit=1048576,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-2.0-flash-lite-preview-02-05',\n",
      "  output_token_limit=8192,\n",
      "  supported_actions=[\n",
      "    'g\n",
      "Modelo #11: name=models/gemini-2.0-flash-lite-preview\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Preview release (February 5th, 2025) of Gemini 2.0 Flash-Lite',\n",
      "  display_name='Gemini 2.0 Flash-Lite Preview',\n",
      "  input_token_limit=1048576,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-2.0-flash-lite-preview',\n",
      "  output_token_limit=8192,\n",
      "  supported_actions=[\n",
      "    'generateConte\n",
      "Modelo #12: name=models/gemini-exp-1206\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro',\n",
      "  display_name='Gemini Experimental 1206',\n",
      "  input_token_limit=1048576,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-exp-1206',\n",
      "  output_token_limit=65536,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'countTokens'\n",
      "Modelo #13: name=models/gemini-2.5-flash-preview-tts\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Gemini 2.5 Flash Preview TTS',\n",
      "  display_name='Gemini 2.5 Flash Preview TTS',\n",
      "  input_token_limit=8192,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-2.5-flash-preview-tts',\n",
      "  output_token_limit=16384,\n",
      "  supported_actions=[\n",
      "    'countTokens',\n",
      "    'generateContent',\n",
      "  ],\n",
      "  temper\n",
      "Modelo #14: name=models/gemini-2.5-pro-preview-tts\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Gemini 2.5 Pro Preview TTS',\n",
      "  display_name='Gemini 2.5 Pro Preview TTS',\n",
      "  input_token_limit=8192,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-2.5-pro-preview-tts',\n",
      "  output_token_limit=16384,\n",
      "  supported_actions=[\n",
      "    'countTokens',\n",
      "    'generateContent',\n",
      "    'batchGenerateC\n",
      "Modelo #15: name=models/gemma-3-1b-it\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  display_name='Gemma 3 1B',\n",
      "  input_token_limit=32768,\n",
      "  name='models/gemma-3-1b-it',\n",
      "  output_token_limit=8192,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'countTokens',\n",
      "  ],\n",
      "  temperature=1.0,\n",
      "  top_k=64,\n",
      "  top_p=0.95,\n",
      "  tuned_model_info=TunedModelInfo(),\n",
      "  version='001'\n",
      ")\n",
      "Modelo #16: name=models/gemma-3-4b-it\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  display_name='Gemma 3 4B',\n",
      "  input_token_limit=32768,\n",
      "  name='models/gemma-3-4b-it',\n",
      "  output_token_limit=8192,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'countTokens',\n",
      "  ],\n",
      "  temperature=1.0,\n",
      "  top_k=64,\n",
      "  top_p=0.95,\n",
      "  tuned_model_info=TunedModelInfo(),\n",
      "  version='001'\n",
      ")\n",
      "Modelo #17: name=models/gemma-3-12b-it\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  display_name='Gemma 3 12B',\n",
      "  input_token_limit=32768,\n",
      "  name='models/gemma-3-12b-it',\n",
      "  output_token_limit=8192,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'countTokens',\n",
      "  ],\n",
      "  temperature=1.0,\n",
      "  top_k=64,\n",
      "  top_p=0.95,\n",
      "  tuned_model_info=TunedModelInfo(),\n",
      "  version='001'\n",
      ")\n",
      "Modelo #18: name=models/gemma-3-27b-it\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  display_name='Gemma 3 27B',\n",
      "  input_token_limit=131072,\n",
      "  name='models/gemma-3-27b-it',\n",
      "  output_token_limit=8192,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'countTokens',\n",
      "  ],\n",
      "  temperature=1.0,\n",
      "  top_k=64,\n",
      "  top_p=0.95,\n",
      "  tuned_model_info=TunedModelInfo(),\n",
      "  version='001'\n",
      ")\n",
      "Modelo #19: name=models/gemma-3n-e4b-it\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  display_name='Gemma 3n E4B',\n",
      "  input_token_limit=8192,\n",
      "  name='models/gemma-3n-e4b-it',\n",
      "  output_token_limit=2048,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'countTokens',\n",
      "  ],\n",
      "  temperature=1.0,\n",
      "  top_k=64,\n",
      "  top_p=0.95,\n",
      "  tuned_model_info=TunedModelInfo(),\n",
      "  version='001'\n",
      ")\n",
      "Modelo #20: name=models/gemma-3n-e2b-it\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  display_name='Gemma 3n E2B',\n",
      "  input_token_limit=8192,\n",
      "  name='models/gemma-3n-e2b-it',\n",
      "  output_token_limit=2048,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'countTokens',\n",
      "  ],\n",
      "  temperature=1.0,\n",
      "  top_k=64,\n",
      "  top_p=0.95,\n",
      "  tuned_model_info=TunedModelInfo(),\n",
      "  version='001'\n",
      ")\n",
      "Modelo #21: name=models/gemini-flash-latest\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Latest release of Gemini Flash',\n",
      "  display_name='Gemini Flash Latest',\n",
      "  input_token_limit=1048576,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-flash-latest',\n",
      "  output_token_limit=65536,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'countTokens',\n",
      "    'createCachedContent',\n",
      "Modelo #22: name=models/gemini-flash-lite-latest\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Latest release of Gemini Flash-Lite',\n",
      "  display_name='Gemini Flash-Lite Latest',\n",
      "  input_token_limit=1048576,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-flash-lite-latest',\n",
      "  output_token_limit=65536,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'countTokens',\n",
      "    'create\n",
      "Modelo #23: name=models/gemini-pro-latest\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Latest release of Gemini Pro',\n",
      "  display_name='Gemini Pro Latest',\n",
      "  input_token_limit=1048576,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-pro-latest',\n",
      "  output_token_limit=65536,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'countTokens',\n",
      "    'createCachedContent',\n",
      "    '\n",
      "Modelo #24: name=models/gemini-2.5-flash-lite\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Stable version of Gemini 2.5 Flash-Lite, released in July of 2025',\n",
      "  display_name='Gemini 2.5 Flash-Lite',\n",
      "  input_token_limit=1048576,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-2.5-flash-lite',\n",
      "  output_token_limit=65536,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'c\n",
      "Modelo #25: name=models/gemini-2.5-flash-image-preview\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Gemini 2.5 Flash Preview Image',\n",
      "  display_name='Nano Banana',\n",
      "  input_token_limit=32768,\n",
      "  max_temperature=1.0,\n",
      "  name='models/gemini-2.5-flash-image-preview',\n",
      "  output_token_limit=32768,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'countTokens',\n",
      "    'batchGenerateContent\n",
      "Modelo #26: name=models/gemini-2.5-flash-image\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Gemini 2.5 Flash Preview Image',\n",
      "  display_name='Nano Banana',\n",
      "  input_token_limit=32768,\n",
      "  max_temperature=1.0,\n",
      "  name='models/gemini-2.5-flash-image',\n",
      "  output_token_limit=32768,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'countTokens',\n",
      "    'batchGenerateContent',\n",
      "  ],\n",
      "\n",
      "Modelo #27: name=models/gemini-2.5-flash-preview-09-2025\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Gemini 2.5 Flash Preview Sep 2025',\n",
      "  display_name='Gemini 2.5 Flash Preview Sep 2025',\n",
      "  input_token_limit=1048576,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-2.5-flash-preview-09-2025',\n",
      "  output_token_limit=65536,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'countToken\n",
      "Modelo #28: name=models/gemini-2.5-flash-lite-preview-09-2025\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Preview release (Septempber 25th, 2025) of Gemini 2.5 Flash-Lite',\n",
      "  display_name='Gemini 2.5 Flash-Lite Preview Sep 2025',\n",
      "  input_token_limit=1048576,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-2.5-flash-lite-preview-09-2025',\n",
      "  output_token_limit=65536,\n",
      "  supported_actions\n",
      "Modelo #29: name=models/gemini-3-pro-preview\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Gemini 3 Pro Preview',\n",
      "  display_name='Gemini 3 Pro Preview',\n",
      "  input_token_limit=1048576,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-3-pro-preview',\n",
      "  output_token_limit=65536,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'countTokens',\n",
      "    'createCachedContent',\n",
      "    'ba\n",
      "Modelo #30: name=models/gemini-3-flash-preview\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Gemini 3 Flash Preview',\n",
      "  display_name='Gemini 3 Flash Preview',\n",
      "  input_token_limit=1048576,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-3-flash-preview',\n",
      "  output_token_limit=65536,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'countTokens',\n",
      "    'createCachedContent',\n",
      " \n",
      "Modelo #31: name=models/gemini-3-pro-image-preview\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Gemini 3 Pro Image Preview',\n",
      "  display_name='Nano Banana Pro',\n",
      "  input_token_limit=131072,\n",
      "  max_temperature=1.0,\n",
      "  name='models/gemini-3-pro-image-preview',\n",
      "  output_token_limit=32768,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'countTokens',\n",
      "    'batchGenerateContent',\n",
      "\n",
      "Modelo #32: name=models/nano-banana-pro-preview\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Gemini 3 Pro Image Preview',\n",
      "  display_name='Nano Banana Pro',\n",
      "  input_token_limit=131072,\n",
      "  max_temperature=1.0,\n",
      "  name='models/nano-banana-pro-preview',\n",
      "  output_token_limit=32768,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'countTokens',\n",
      "    'batchGenerateContent',\n",
      "  ]\n",
      "Modelo #33: name=models/gemini-robotics-er-1.5-preview\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Gemini Robotics-ER 1.5 Preview',\n",
      "  display_name='Gemini Robotics-ER 1.5 Preview',\n",
      "  input_token_limit=1048576,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-robotics-er-1.5-preview',\n",
      "  output_token_limit=65536,\n",
      "  supported_actions=[\n",
      "    'generateContent',\n",
      "    'countTokens',\n",
      "  ],\n",
      "Modelo #34: name=models/gemini-2.5-computer-use-preview-10-2025\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Gemini 2.5 Computer Use Preview 10-2025',\n",
      "  display_name='Gemini 2.5 Computer Use Preview 10-2025',\n",
      "  input_token_limit=131072,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-2.5-computer-use-preview-10-2025',\n",
      "  output_token_limit=65536,\n",
      "  supported_actions=[\n",
      "    'generateContent\n",
      "Modelo #35: name=models/deep-research-pro-preview-12-2025\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Preview release (December 12th, 2025) of Deep Research Pro',\n",
      "  display_name='Deep Research Pro Preview (Dec-12-2025)',\n",
      "  input_token_limit=131072,\n",
      "  max_temperature=2.0,\n",
      "  name='models/deep-research-pro-preview-12-2025',\n",
      "  output_token_limit=65536,\n",
      "  supported_actions=[\n",
      "    'ge\n",
      "Modelo #36: name=models/embedding-001\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Obtain a distributed representation of a text.',\n",
      "  display_name='Embedding 001',\n",
      "  input_token_limit=2048,\n",
      "  name='models/embedding-001',\n",
      "  output_token_limit=1,\n",
      "  supported_actions=[\n",
      "    'embedContent',\n",
      "  ],\n",
      "  tuned_model_info=TunedModelInfo(),\n",
      "  version='001'\n",
      ")\n",
      "Modelo #37: name=models/text-embedding-004\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Obtain a distributed representation of a text.',\n",
      "  display_name='Text Embedding 004',\n",
      "  input_token_limit=2048,\n",
      "  name='models/text-embedding-004',\n",
      "  output_token_limit=1,\n",
      "  supported_actions=[\n",
      "    'embedContent',\n",
      "  ],\n",
      "  tuned_model_info=TunedModelInfo(),\n",
      "  version='004'\n",
      ")\n",
      "Modelo #38: name=models/gemini-embedding-exp-03-07\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Obtain a distributed representation of a text.',\n",
      "  display_name='Gemini Embedding Experimental 03-07',\n",
      "  input_token_limit=8192,\n",
      "  name='models/gemini-embedding-exp-03-07',\n",
      "  output_token_limit=1,\n",
      "  supported_actions=[\n",
      "    'embedContent',\n",
      "    'countTextTokens',\n",
      "    'countTokens\n",
      "Modelo #39: name=models/gemini-embedding-exp\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Obtain a distributed representation of a text.',\n",
      "  display_name='Gemini Embedding Experimental',\n",
      "  input_token_limit=8192,\n",
      "  name='models/gemini-embedding-exp',\n",
      "  output_token_limit=1,\n",
      "  supported_actions=[\n",
      "    'embedContent',\n",
      "    'countTextTokens',\n",
      "    'countTokens',\n",
      "  ],\n",
      "  tu\n",
      "Modelo #40: name=models/gemini-embedding-001\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Obtain a distributed representation of a text.',\n",
      "  display_name='Gemini Embedding 001',\n",
      "  input_token_limit=2048,\n",
      "  name='models/gemini-embedding-001',\n",
      "  output_token_limit=1,\n",
      "  supported_actions=[\n",
      "    'embedContent',\n",
      "    'countTextTokens',\n",
      "    'countTokens',\n",
      "    'asyncBatchEmb\n",
      "Modelo #41: name=models/aqa\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Model trained to return answers to questions that are grounded in provided sources, along with estimating answerable probability.',\n",
      "  display_name='Model that performs Attributed Question Answering.',\n",
      "  input_token_limit=7168,\n",
      "  name='models/aqa',\n",
      "  output_token_limit=1024,\n",
      "  s\n",
      "Modelo #42: name=models/imagen-4.0-generate-preview-06-06\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Vertex served Imagen 4.0 model',\n",
      "  display_name='Imagen 4 (Preview)',\n",
      "  input_token_limit=480,\n",
      "  name='models/imagen-4.0-generate-preview-06-06',\n",
      "  output_token_limit=8192,\n",
      "  supported_actions=[\n",
      "    'predict',\n",
      "  ],\n",
      "  tuned_model_info=TunedModelInfo(),\n",
      "  version='01'\n",
      ")\n",
      "Modelo #43: name=models/imagen-4.0-ultra-generate-preview-06-06\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Vertex served Imagen 4.0 ultra model',\n",
      "  display_name='Imagen 4 Ultra (Preview)',\n",
      "  input_token_limit=480,\n",
      "  name='models/imagen-4.0-ultra-generate-preview-06-06',\n",
      "  output_token_limit=8192,\n",
      "  supported_actions=[\n",
      "    'predict',\n",
      "  ],\n",
      "  tuned_model_info=TunedModelInfo(),\n",
      "  versio\n",
      "Modelo #44: name=models/imagen-4.0-generate-001\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Vertex served Imagen 4.0 model',\n",
      "  display_name='Imagen 4',\n",
      "  input_token_limit=480,\n",
      "  name='models/imagen-4.0-generate-001',\n",
      "  output_token_limit=8192,\n",
      "  supported_actions=[\n",
      "    'predict',\n",
      "  ],\n",
      "  tuned_model_info=TunedModelInfo(),\n",
      "  version='001'\n",
      ")\n",
      "Modelo #45: name=models/imagen-4.0-ultra-generate-001\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Vertex served Imagen 4.0 ultra model',\n",
      "  display_name='Imagen 4 Ultra',\n",
      "  input_token_limit=480,\n",
      "  name='models/imagen-4.0-ultra-generate-001',\n",
      "  output_token_limit=8192,\n",
      "  supported_actions=[\n",
      "    'predict',\n",
      "  ],\n",
      "  tuned_model_info=TunedModelInfo(),\n",
      "  version='001'\n",
      ")\n",
      "Modelo #46: name=models/imagen-4.0-fast-generate-001\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Vertex served Imagen 4.0 Fast model',\n",
      "  display_name='Imagen 4 Fast',\n",
      "  input_token_limit=480,\n",
      "  name='models/imagen-4.0-fast-generate-001',\n",
      "  output_token_limit=8192,\n",
      "  supported_actions=[\n",
      "    'predict',\n",
      "  ],\n",
      "  tuned_model_info=TunedModelInfo(),\n",
      "  version='001'\n",
      ")\n",
      "Modelo #47: name=models/veo-2.0-generate-001\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Vertex served Veo 2 model. Access to this model requires billing to be enabled on the associated Google Cloud Platform account. Please visit https://console.cloud.google.com/billing to enable it.',\n",
      "  display_name='Veo 2',\n",
      "  input_token_limit=480,\n",
      "  name='models/veo-2.0-generate\n",
      "Modelo #48: name=models/veo-3.0-generate-001\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Veo 3',\n",
      "  display_name='Veo 3',\n",
      "  input_token_limit=480,\n",
      "  name='models/veo-3.0-generate-001',\n",
      "  output_token_limit=8192,\n",
      "  supported_actions=[\n",
      "    'predictLongRunning',\n",
      "  ],\n",
      "  tuned_model_info=TunedModelInfo(),\n",
      "  version='3.0'\n",
      ")\n",
      "Modelo #49: name=models/veo-3.0-fast-generate-001\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Veo 3 fast',\n",
      "  display_name='Veo 3 fast',\n",
      "  input_token_limit=480,\n",
      "  name='models/veo-3.0-fast-generate-001',\n",
      "  output_token_limit=8192,\n",
      "  supported_actions=[\n",
      "    'predictLongRunning',\n",
      "  ],\n",
      "  tuned_model_info=TunedModelInfo(),\n",
      "  version='3.0'\n",
      ")\n",
      "Modelo #50: name=models/veo-3.1-generate-preview\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Veo 3.1',\n",
      "  display_name='Veo 3.1',\n",
      "  input_token_limit=480,\n",
      "  name='models/veo-3.1-generate-preview',\n",
      "  output_token_limit=8192,\n",
      "  supported_actions=[\n",
      "    'predictLongRunning',\n",
      "  ],\n",
      "  tuned_model_info=TunedModelInfo(),\n",
      "  version='3.1'\n",
      ")\n",
      "Modelo #51: name=models/veo-3.1-fast-generate-preview\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Veo 3.1 fast',\n",
      "  display_name='Veo 3.1 fast',\n",
      "  input_token_limit=480,\n",
      "  name='models/veo-3.1-fast-generate-preview',\n",
      "  output_token_limit=8192,\n",
      "  supported_actions=[\n",
      "    'predictLongRunning',\n",
      "  ],\n",
      "  tuned_model_info=TunedModelInfo(),\n",
      "  version='3.1'\n",
      ")\n",
      "Modelo #52: name=models/gemini-2.5-flash-native-audio-latest\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Latest release of Gemini 2.5 Flash Native Audio',\n",
      "  display_name='Gemini 2.5 Flash Native Audio Latest',\n",
      "  input_token_limit=131072,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-2.5-flash-native-audio-latest',\n",
      "  output_token_limit=8192,\n",
      "  supported_actions=[\n",
      "    'countTokens',\n",
      "\n",
      "Modelo #53: name=models/gemini-2.5-flash-native-audio-preview-09-2025\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Gemini 2.5 Flash Native Audio Preview 09-2025',\n",
      "  display_name='Gemini 2.5 Flash Native Audio Preview 09-2025',\n",
      "  input_token_limit=131072,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-2.5-flash-native-audio-preview-09-2025',\n",
      "  output_token_limit=8192,\n",
      "  supported_actions=[\n",
      "   \n",
      "Modelo #54: name=models/gemini-2.5-flash-native-audio-preview-12-2025\n",
      "  supported_generation_methods: None\n",
      "  repr: Model(\n",
      "  description='Gemini 2.5 Flash Native Audio Preview 12-2025',\n",
      "  display_name='Gemini 2.5 Flash Native Audio Preview 12-2025',\n",
      "  input_token_limit=131072,\n",
      "  max_temperature=2.0,\n",
      "  name='models/gemini-2.5-flash-native-audio-preview-12-2025',\n",
      "  output_token_limit=8192,\n",
      "  supported_actions=[\n",
      "   \n",
      "--- FIN DIAGNÓSTICO ---\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import google.genai as genai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "api_key = os.environ.get(\"GEMINI_API_KEY\")\n",
    "print(\"GEMINI_API_KEY found:\", bool(api_key))\n",
    "if api_key:\n",
    "    print(\"GEMINI_API_KEY (partial):\", api_key[:4] + \"...\")\n",
    "else:\n",
    "    print(\"Warning: GEMINI_API_KEY not found in environment\")\n",
    "\n",
    "client = None\n",
    "if api_key:\n",
    "    try:\n",
    "        client = genai.Client(api_key=api_key)\n",
    "    except Exception as e:\n",
    "        print(\"Error creating client:\", type(e).__name__, e)\n",
    "\n",
    "print(\"--- MODELOS DISPONIBLES EN TU CUENTA ---\")\n",
    "if not client:\n",
    "    print(\"No se creó cliente; revisa la API key y permisos.\")\n",
    "else:\n",
    "    try:\n",
    "        models_iter = client.models.list()\n",
    "        models = list(models_iter)\n",
    "        print(\"Número de modelos recibidos:\", len(models))\n",
    "        if not models:\n",
    "            print(\"Lista vacía. Puede que tu cuenta no tenga modelos con esos permisos o haya un problema de permisos.\")\n",
    "        for i, m in enumerate(models, 1):\n",
    "            name = getattr(m, \"name\", None)\n",
    "            methods = getattr(m, \"supported_generation_methods\", None)\n",
    "            print(f\"Modelo #{i}: name={name}\")\n",
    "            print(\"  supported_generation_methods:\", methods)\n",
    "            # Mostrar una vista corta del objeto para diagnosticar\n",
    "            try:\n",
    "                print(\"  repr:\", repr(m)[:300])\n",
    "            except Exception:\n",
    "                print(\"  (no se pudo repr el objeto)\")\n",
    "    except Exception as e:\n",
    "        print(\"Error al listar modelos:\", type(e).__name__, e)\n",
    "\n",
    "print(\"--- FIN DIAGNÓSTICO ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310b689d",
   "metadata": {},
   "source": [
    "\n",
    "-- 1. Habilitar extensión de vectores\n",
    "create extension if not exists vector;\n",
    "\n",
    "-- 2. Borrar la tabla si existe (para empezar de cero)\n",
    "drop table if exists documentos_dj;\n",
    "\n",
    "-- 3. Crear la tabla NUEVA (Estructura correcta para tu Excel)\n",
    "create table documentos_dj (\n",
    "  id bigserial primary key,\n",
    "  content text,\n",
    "  metadata jsonb,\n",
    "  embedding vector(768) -- Coincide con tu dimensión\n",
    ");\n",
    "\n",
    "-- 4. Crear el índice de búsqueda rápida\n",
    "create index on documentos_dj using hnsw (embedding vector_cosine_ops);\n",
    "\n",
    "-- 5. Habilitar permisos (CRUCIAL para que Python pueda escribir)\n",
    "grant all on table documentos_dj to anon, authenticated, service_role;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d86b02",
   "metadata": {},
   "source": [
    "create or replace function match_documentos (\n",
    "  query_embedding vector(768),\n",
    "  match_threshold float,\n",
    "  match_count int\n",
    ")\n",
    "returns table (\n",
    "  id bigint,\n",
    "  content text,\n",
    "  metadata jsonb,\n",
    "  similarity float\n",
    ")\n",
    "language plpgsql\n",
    "as $$\n",
    "begin\n",
    "  return query\n",
    "  select\n",
    "    documentos_dj.id,\n",
    "    documentos_dj.content,\n",
    "    documentos_dj.metadata,\n",
    "    1 - (documentos_dj.embedding <=> query_embedding) as similarity\n",
    "  from documents_dj\n",
    "  where 1 - (documentos_dj.embedding <=> query_embedding) > match_threshold\n",
    "  order by documentos_dj.embedding <=> query_embedding\n",
    "  limit match_count;\n",
    "end;\n",
    "$$;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bd3efc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 200\n",
      "Response JSON:\n",
      "{'object': 'list', 'data': [{'id': 'deepseek-chat', 'object': 'model', 'owned_by': 'deepseek'}, {'id': 'deepseek-reasoner', 'object': 'model', 'owned_by': 'deepseek'}]}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Cargar variables desde .env\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "# Obtener API Key\n",
    "api_key = os.environ.get(\"DEEPSEEK_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"No se encontró DEEPSEEK_API_KEY en el archivo .env\")\n",
    "\n",
    "# Endpoint\n",
    "url = \"https://api.deepseek.com/models\"\n",
    "\n",
    "# Headers\n",
    "headers = {\n",
    "    \"Accept\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "\n",
    "# Petición GET\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# Mostrar resultado\n",
    "print(\"Status:\", response.status_code)\n",
    "print(\"Response JSON:\")\n",
    "print(response.json())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
